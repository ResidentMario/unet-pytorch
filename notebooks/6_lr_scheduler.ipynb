{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our next addition to the model is a learning rate scheduler. Specifically, we'll use the one-cycle learning rate policy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ../models/model_6.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ../models/model_6.py\n",
    "\n",
    "# number of epochs of training\n",
    "NUM_EPOCHS = 50\n",
    "\n",
    "import torch\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from torchvision import transforms\n",
    "\n",
    "\n",
    "class BobRossSegmentedImagesDataset(Dataset):\n",
    "    def __init__(self, dataroot):\n",
    "        super().__init__()\n",
    "        self.dataroot = dataroot\n",
    "        self.imgs = list((self.dataroot / 'train' / 'images').rglob('*.png'))\n",
    "        self.segs = list((self.dataroot / 'train' / 'labels').rglob('*.png'))\n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.Resize((164, 164)),\n",
    "            transforms.Pad(46, padding_mode='reflect'),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(\n",
    "                            mean=(0.459387, 0.46603974, 0.4336706),\n",
    "                            std=(0.06098535, 0.05802868, 0.08737113)\n",
    "            )\n",
    "        ])\n",
    "        self.color_key = {\n",
    "            3 : 0,\n",
    "            5: 1,\n",
    "            10: 2,\n",
    "            14: 3,\n",
    "            17: 4,\n",
    "            18: 5,\n",
    "            22: 6,\n",
    "            27: 7,\n",
    "            61: 8\n",
    "        }\n",
    "        assert len(self.imgs) == len(self.segs)\n",
    "        # TODO: remean images to N(0, 1)?\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.imgs)\n",
    "    \n",
    "    def __getitem__(self, i):\n",
    "        def translate(x):\n",
    "            return self.color_key[x]\n",
    "        translate = np.vectorize(translate)\n",
    "        \n",
    "        img = Image.open(self.imgs[i])\n",
    "        img = self.transform(img)\n",
    "        \n",
    "        seg = Image.open(self.segs[i])\n",
    "        seg = seg.resize((256, 256))\n",
    "        \n",
    "        # Labels are in the ADE20K ontology and are not consequetive,\n",
    "        # we have to apply a remap operation over the labels in a just-in-time\n",
    "        # manner. This slows things down, but it's fine, this is just a demo\n",
    "        # anyway.\n",
    "        seg = translate(np.array(seg)).astype('int64')\n",
    "        \n",
    "        # One-hot encode the segmentation mask.\n",
    "        # def ohe_mat(segmap):\n",
    "        #     return np.array(\n",
    "        #         list(\n",
    "        #             np.array(segmap) == i for i in range(9)\n",
    "        #         )\n",
    "        #     ).astype(int).reshape(9, 256, 256)\n",
    "        # seg = ohe_mat(seg)\n",
    "        \n",
    "        # Additionally, the original UNet implementation outputs a segmentation map\n",
    "        # for a subset of the overall image, not the image as a whole! With this input\n",
    "        # size the segmentation map targeted is a (164, 164) center crop.\n",
    "        seg = seg[46:210, 46:210]\n",
    "        \n",
    "        return img, seg\n",
    "    \n",
    "from torch import nn\n",
    "\n",
    "class UNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv_1_1 = nn.Conv2d(3, 64, 3)\n",
    "        torch.nn.init.kaiming_normal_(self.conv_1_1.weight)\n",
    "        self.relu_1_2 = nn.ReLU()\n",
    "        self.norm_1_3 = nn.BatchNorm2d(64)\n",
    "        self.conv_1_4 = nn.Conv2d(64, 64, 3)\n",
    "        torch.nn.init.kaiming_normal_(self.conv_1_4.weight)\n",
    "        self.relu_1_5 = nn.ReLU()\n",
    "        self.norm_1_6 = nn.BatchNorm2d(64)\n",
    "        self.pool_1_7 = nn.MaxPool2d(2)\n",
    "        \n",
    "        self.conv_2_1 = nn.Conv2d(64, 128, 3)\n",
    "        torch.nn.init.kaiming_normal_(self.conv_2_1.weight)        \n",
    "        self.relu_2_2 = nn.ReLU()\n",
    "        self.norm_2_3 = nn.BatchNorm2d(128)\n",
    "        self.conv_2_4 = nn.Conv2d(128, 128, 3)\n",
    "        torch.nn.init.kaiming_normal_(self.conv_2_4.weight)        \n",
    "        self.relu_2_5 = nn.ReLU()\n",
    "        self.norm_2_6 = nn.BatchNorm2d(128)\n",
    "        self.pool_2_7 = nn.MaxPool2d(2)\n",
    "        \n",
    "        self.conv_3_1 = nn.Conv2d(128, 256, 3)\n",
    "        torch.nn.init.kaiming_normal_(self.conv_3_1.weight)\n",
    "        self.relu_3_2 = nn.ReLU()\n",
    "        self.norm_3_3 = nn.BatchNorm2d(256)\n",
    "        self.conv_3_4 = nn.Conv2d(256, 256, 3)\n",
    "        torch.nn.init.kaiming_normal_(self.conv_3_4.weight)\n",
    "        self.relu_3_5 = nn.ReLU()\n",
    "        self.norm_3_6 = nn.BatchNorm2d(256)\n",
    "        self.pool_3_7 = nn.MaxPool2d(2)\n",
    "        \n",
    "        self.conv_4_1 = nn.Conv2d(256, 512, 3)\n",
    "        torch.nn.init.kaiming_normal_(self.conv_4_1.weight)\n",
    "        self.relu_4_2 = nn.ReLU()\n",
    "        self.norm_4_3 = nn.BatchNorm2d(512)\n",
    "        self.conv_4_4 = nn.Conv2d(512, 512, 3)\n",
    "        torch.nn.init.kaiming_normal_(self.conv_4_4.weight)\n",
    "        self.relu_4_5 = nn.ReLU()\n",
    "        self.norm_4_6 = nn.BatchNorm2d(512)\n",
    "        \n",
    "        # deconv is the '2D transposed convolution operator'\n",
    "        self.deconv_5_1 = nn.ConvTranspose2d(512, 256, (2, 2), 2)\n",
    "        # 61x61 -> 48x48 crop\n",
    "        self.c_crop_5_2 = lambda x: x[:, :, 6:54, 6:54]\n",
    "        self.concat_5_3 = lambda x, y: torch.cat((x, y), dim=1)\n",
    "        self.conv_5_4 = nn.Conv2d(512, 256, 3)\n",
    "        torch.nn.init.kaiming_normal_(self.conv_5_4.weight)        \n",
    "        self.relu_5_5 = nn.ReLU()\n",
    "        self.norm_5_6 = nn.BatchNorm2d(256)\n",
    "        self.conv_5_7 = nn.Conv2d(256, 256, 3)\n",
    "        torch.nn.init.kaiming_normal_(self.conv_5_7.weight)\n",
    "        self.relu_5_8 = nn.ReLU()\n",
    "        self.norm_5_9 = nn.BatchNorm2d(256)\n",
    "        \n",
    "        self.deconv_6_1 = nn.ConvTranspose2d(256, 128, (2, 2), 2)\n",
    "        # 121x121 -> 88x88 crop\n",
    "        self.c_crop_6_2 = lambda x: x[:, :, 17:105, 17:105]\n",
    "        self.concat_6_3 = lambda x, y: torch.cat((x, y), dim=1)\n",
    "        self.conv_6_4 = nn.Conv2d(256, 128, 3)\n",
    "        torch.nn.init.kaiming_normal_(self.conv_6_4.weight)\n",
    "        self.relu_6_5 = nn.ReLU()\n",
    "        self.norm_6_6 = nn.BatchNorm2d(128)\n",
    "        self.conv_6_7 = nn.Conv2d(128, 128, 3)\n",
    "        torch.nn.init.kaiming_normal_(self.conv_6_7.weight)\n",
    "        self.relu_6_8 = nn.ReLU()\n",
    "        self.norm_6_9 = nn.BatchNorm2d(128)\n",
    "        \n",
    "        self.deconv_7_1 = nn.ConvTranspose2d(128, 64, (2, 2), 2)\n",
    "        # 252x252 -> 168x168 crop\n",
    "        self.c_crop_7_2 = lambda x: x[:, :, 44:212, 44:212]\n",
    "        self.concat_7_3 = lambda x, y: torch.cat((x, y), dim=1)\n",
    "        self.conv_7_4 = nn.Conv2d(128, 64, 3)\n",
    "        torch.nn.init.kaiming_normal_(self.conv_7_4.weight)\n",
    "        self.relu_7_5 = nn.ReLU()\n",
    "        self.norm_7_6 = nn.BatchNorm2d(64)\n",
    "        self.conv_7_7 = nn.Conv2d(64, 64, 3)\n",
    "        torch.nn.init.kaiming_normal_(self.conv_7_7.weight)        \n",
    "        self.relu_7_8 = nn.ReLU()\n",
    "        self.norm_7_9 = nn.BatchNorm2d(64)\n",
    "        \n",
    "        # 1x1 conv ~= fc; n_classes = 9\n",
    "        self.conv_8_1 = nn.Conv2d(64, 9, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv_1_1(x)\n",
    "        x = self.relu_1_2(x)\n",
    "        x = self.norm_1_3(x)\n",
    "        x = self.conv_1_4(x)\n",
    "        x = self.relu_1_5(x)\n",
    "        x_residual_1 = self.norm_1_6(x)\n",
    "        x = self.pool_1_7(x_residual_1)\n",
    "        \n",
    "        x = self.conv_2_1(x)\n",
    "        x = self.relu_2_2(x)\n",
    "        x = self.norm_2_3(x)\n",
    "        x = self.conv_2_4(x)\n",
    "        x = self.relu_2_5(x)\n",
    "        x_residual_2 = self.norm_2_6(x)\n",
    "        x = self.pool_2_7(x_residual_2)\n",
    "        \n",
    "        x = self.conv_3_1(x)\n",
    "        x = self.relu_3_2(x)\n",
    "        x = self.norm_3_3(x)\n",
    "        x = self.conv_3_4(x)\n",
    "        x = self.relu_3_5(x)\n",
    "        x_residual_3 = self.norm_3_6(x)\n",
    "        x = self.pool_3_7(x_residual_3)\n",
    "        \n",
    "        x = self.conv_4_1(x)\n",
    "        x = self.relu_4_2(x)\n",
    "        x = self.norm_4_3(x)        \n",
    "        x = self.conv_4_4(x)\n",
    "        x = self.relu_4_5(x)\n",
    "        x = self.norm_4_6(x)\n",
    "        \n",
    "        x = self.deconv_5_1(x)\n",
    "        x = self.concat_5_3(self.c_crop_5_2(x_residual_3), x)\n",
    "        x = self.conv_5_4(x)\n",
    "        x = self.relu_5_5(x)\n",
    "        x = self.norm_5_6(x)\n",
    "        x = self.conv_5_7(x)\n",
    "        x = self.relu_5_8(x)\n",
    "        x = self.norm_5_9(x)\n",
    "        \n",
    "        x = self.deconv_6_1(x)\n",
    "        x = self.concat_6_3(self.c_crop_6_2(x_residual_2), x)\n",
    "        x = self.conv_6_4(x)\n",
    "        x = self.relu_6_5(x)\n",
    "        x = self.norm_6_6(x)\n",
    "        x = self.conv_6_7(x)\n",
    "        x = self.relu_6_8(x)\n",
    "        x = self.norm_6_9(x)\n",
    "        \n",
    "        x = self.deconv_7_1(x)\n",
    "        x = self.concat_7_3(self.c_crop_7_2(x_residual_1), x)\n",
    "        x = self.conv_7_4(x)\n",
    "        x = self.relu_7_5(x)\n",
    "        x = self.norm_7_6(x)\n",
    "        x = self.conv_7_7(x)\n",
    "        x = self.relu_7_8(x)\n",
    "        x = self.norm_7_9(x)\n",
    "        \n",
    "        x = self.conv_8_1(x)\n",
    "        return x\n",
    "\n",
    "    \n",
    "from pathlib import Path\n",
    "dataroot = Path('/spell/bob-ross-kaggle-dataset/')\n",
    "dataset = BobRossSegmentedImagesDataset(dataroot)\n",
    "dataloader = DataLoader(dataset, shuffle=True, batch_size=8)\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import KFold\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "\n",
    "writer = SummaryWriter(f'/spell/tensorboards/experiment_6')\n",
    "model = UNet()\n",
    "model.cuda()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.5)\n",
    "scheduler = optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=32)\n",
    "\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    losses = []\n",
    "\n",
    "    for i, (batch, segmap) in enumerate(dataloader):\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        batch = batch.cuda()\n",
    "        segmap = segmap.cuda()\n",
    "\n",
    "        output = model(batch)\n",
    "        loss = criterion(output, segmap)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "        curr_loss = loss.item()\n",
    "        if i % 50 == 0:\n",
    "            print(\n",
    "                f'Finished epoch {epoch}, batch {i}. Loss: {curr_loss:.3f}.'\n",
    "            )\n",
    "\n",
    "        writer.add_scalar(\n",
    "            'training loss', curr_loss, epoch * len(dataloader) + i\n",
    "        )\n",
    "        losses.append(curr_loss)\n",
    "\n",
    "    print(\n",
    "        f'Finished epoch {epoch}. '\n",
    "        f'avg loss: {np.mean(losses)}; median loss: {np.min(losses)}'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'OneCycleLR'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-c29eb4d40a11>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlr_scheduler\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mOneCycleLR\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'OneCycleLR'"
     ]
    }
   ],
   "source": [
    "from torch.optim.lr_scheduler import OneCycleLR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.2.0'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'torch.optim.lr_scheduler' has no attribute 'OneCycleLR'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-e47646023850>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mscheduler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlr_scheduler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOneCycleLR\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_lr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: module 'torch.optim.lr_scheduler' has no attribute 'OneCycleLR'"
     ]
    }
   ],
   "source": [
    "scheduler = optim.lr_scheduler.OneCycleLR(optimizer, max_lr=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "450990e08693473baf063db6982ad181",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping early, the loss has diverged\n",
      "Learning rate search finished. See the graph with {finder_name}.plot()\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from torch_lr_finder import LRFinder\n",
    "\n",
    "lr_finder = LRFinder(model, optimizer, criterion, device=\"cuda\")\n",
    "lr_finder.range_test(dataloader, end_lr=100, num_iter=100)\n",
    "lr_finder.plot()\n",
    "lr_finder.reset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This LR find operation shows that the optimal cyclical learning rate is in the `(0.1, 0.5)` min-max range. I use this information to set the learning rate policy accordingly.\n",
    "\n",
    "Not all learning rate schedulers in PyTorch are **chainable**. Chainable learning rate schedulers are those which may be combined with one another (chained). The one-cycle learning rate scheduler is not chainable. This means that for example it is not possible to combine it with `ReduceLROnPlateau`. At least not trivially...it is possible to do it by staging the training, and using this learning rate scheduler in place of that one late in the training. [See this GH issue](https://github.com/pytorch/pytorch/issues/13022).\n",
    "\n",
    "The one-cycle learning rate scheduler is a new contribution to the package! You need at least PyTorch version 1.3.0 to have it, whilst the default environment in Spell is PyTorch 1.4.0. So we have to add `torch==1.4.0` to our run to get the right version onboarded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0mHello, Aleksey Bilogur!\n",
      "\u001b[0m\u001b[0m"
     ]
    }
   ],
   "source": [
    "!spell login --identity #### --password ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m💫 Casting spell #170…\n",
      "\u001b[0m✨ Stop viewing logs with ^C\n",
      "\u001b[0m\u001b[K\u001b[0m\u001b[?25h\u001b[0m✨ Machine_Requested… done -- waiting for a V100 machine.\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\n",
      "\u001b[1m\u001b[36m🌟\u001b[0m Building…   Downloading torch-1.4.0-cp36-cp36m-manylinux1_x86_64.whl (753.4 …[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m^C\n",
      "\u001b[0m\n",
      "\u001b[0m✨ Your run is still running remotely.\n",
      "\u001b[0m✨ Use 'spell kill 170' to terminate your run\n",
      "\u001b[0m✨ Use 'spell logs 170' to view logs again\n",
      "\u001b[0m\u001b[K\u001b[0m\u001b[?25h\u001b[0m\u001b[0m"
     ]
    }
   ],
   "source": [
    "!spell run 'python models/model_6.py'\\\n",
    "    --machine-type 'V100'\\\n",
    "    --pip 'torch==1.4.0'\\\n",
    "    --mount 'uploads/bob-ross-kaggle-dataset':'/spell/bob-ross-kaggle-dataset'\\\n",
    "    --github-url 'https://github.com/ResidentMario/unet-pytorch.git'\\\n",
    "    --tensorboard-dir '/spell/tensorboards/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This failed with \"the NVIDIA driver on your system is too old\". Whoa, that's not good! Unfortunately this means that Spell is incompatible with the one-cycle learning rate scheduler. I will fall back to cosine annealing."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

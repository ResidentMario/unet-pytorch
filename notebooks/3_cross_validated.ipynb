{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook I set up proper cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir ../models/ > /dev/null 2>&1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ../models/model_3.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ../models/model_3.py\n",
    "\n",
    "NUM_EPOCHS = 20\n",
    "NUM_FOLDS = 5\n",
    "\n",
    "\n",
    "import torch\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from torchvision import transforms\n",
    "\n",
    "\n",
    "class BobRossSegmentedImagesDataset(Dataset):\n",
    "    def __init__(self, dataroot):\n",
    "        super().__init__()\n",
    "        self.dataroot = dataroot\n",
    "        self.imgs = list((self.dataroot / 'train' / 'images').rglob('*.png'))\n",
    "        self.segs = list((self.dataroot / 'train' / 'labels').rglob('*.png'))\n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.Resize((256, 256)), transforms.ToTensor()\n",
    "        ])\n",
    "        self.color_key = {\n",
    "            3 : 0,\n",
    "            5: 1,\n",
    "            10: 2,\n",
    "            14: 3,\n",
    "            17: 4,\n",
    "            18: 5,\n",
    "            22: 6,\n",
    "            27: 7,\n",
    "            61: 8\n",
    "        }\n",
    "        assert len(self.imgs) == len(self.segs)\n",
    "        # TODO: remean images to N(0, 1)?\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.imgs)\n",
    "    \n",
    "    def __getitem__(self, i):\n",
    "        def translate(x):\n",
    "            return self.color_key[x]\n",
    "        translate = np.vectorize(translate)\n",
    "        \n",
    "        img = Image.open(self.imgs[i])\n",
    "        img = self.transform(img)\n",
    "        \n",
    "        seg = Image.open(self.segs[i])\n",
    "        seg = seg.resize((256, 256))\n",
    "        \n",
    "        # Labels are in the ADE20K ontology and are not consequetive,\n",
    "        # we have to apply a remap operation over the labels in a just-in-time\n",
    "        # manner. This slows things down, but it's fine, this is just a demo\n",
    "        # anyway.\n",
    "        seg = translate(np.array(seg)).astype('int64')\n",
    "        \n",
    "        # One-hot encode the segmentation mask.\n",
    "        # def ohe_mat(segmap):\n",
    "        #     return np.array(\n",
    "        #         list(\n",
    "        #             np.array(segmap) == i for i in range(9)\n",
    "        #         )\n",
    "        #     ).astype(int).reshape(9, 256, 256)\n",
    "        # seg = ohe_mat(seg)\n",
    "        \n",
    "        # Additionally, the original UNet implementation outputs a segmentation map\n",
    "        # for a subset of the overall image, not the image as a whole! With this input\n",
    "        # size the segmentation map targeted is a (164, 164) center crop.\n",
    "        seg = seg[46:210, 46:210]\n",
    "        \n",
    "        return img, seg\n",
    "    \n",
    "    \n",
    "from torch import nn\n",
    "\n",
    "class UNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv_1_1 = nn.Conv2d(3, 64, 3)\n",
    "        self.relu_1_2 = nn.ReLU()\n",
    "        self.conv_1_3 = nn.Conv2d(64, 64, 3)\n",
    "        self.relu_1_4 = nn.ReLU()\n",
    "        self.pool_1_5 = nn.MaxPool2d(2)\n",
    "        \n",
    "        self.conv_2_1 = nn.Conv2d(64, 128, 3)\n",
    "        self.relu_2_2 = nn.ReLU()\n",
    "        self.conv_2_3 = nn.Conv2d(128, 128, 3)\n",
    "        self.relu_2_4 = nn.ReLU()        \n",
    "        self.pool_2_5 = nn.MaxPool2d(2)\n",
    "        \n",
    "        self.conv_3_1 = nn.Conv2d(128, 256, 3)\n",
    "        self.relu_3_2 = nn.ReLU()\n",
    "        self.conv_3_3 = nn.Conv2d(256, 256, 3)\n",
    "        self.relu_3_4 = nn.ReLU()\n",
    "        self.pool_3_5 = nn.MaxPool2d(2)\n",
    "        \n",
    "        self.conv_4_1 = nn.Conv2d(256, 512, 3)\n",
    "        self.relu_4_2 = nn.ReLU()\n",
    "        self.conv_4_3 = nn.Conv2d(512, 512, 3)\n",
    "        self.relu_4_4 = nn.ReLU()\n",
    "        \n",
    "        # deconv is the '2D transposed convolution operator'\n",
    "        self.deconv_5_1 = nn.ConvTranspose2d(512, 256, (2, 2), 2)\n",
    "        # 61x61 -> 48x48 crop\n",
    "        self.c_crop_5_2 = lambda x: x[:, :, 6:54, 6:54]\n",
    "        self.concat_5_3 = lambda x, y: torch.cat((x, y), dim=1)\n",
    "        self.conv_5_4 = nn.Conv2d(512, 256, 3)\n",
    "        self.relu_5_5 = nn.ReLU()\n",
    "        self.conv_5_6 = nn.Conv2d(256, 256, 3)\n",
    "        self.relu_5_7 = nn.ReLU()\n",
    "        \n",
    "        self.deconv_6_1 = nn.ConvTranspose2d(256, 128, (2, 2), 2)\n",
    "        # 121x121 -> 88x88 crop\n",
    "        self.c_crop_6_2 = lambda x: x[:, :, 17:105, 17:105]\n",
    "        self.concat_6_3 = lambda x, y: torch.cat((x, y), dim=1)\n",
    "        self.conv_6_4 = nn.Conv2d(256, 128, 3)\n",
    "        self.relu_6_5 = nn.ReLU()\n",
    "        self.conv_6_6 = nn.Conv2d(128, 128, 3)\n",
    "        self.relu_6_7 = nn.ReLU()\n",
    "        \n",
    "        self.deconv_7_1 = nn.ConvTranspose2d(128, 64, (2, 2), 2)\n",
    "        # 252x252 -> 168x168 crop\n",
    "        self.c_crop_7_2 = lambda x: x[:, :, 44:212, 44:212]\n",
    "        self.concat_7_3 = lambda x, y: torch.cat((x, y), dim=1)\n",
    "        self.conv_7_4 = nn.Conv2d(128, 64, 3)\n",
    "        self.relu_7_5 = nn.ReLU()\n",
    "        self.conv_7_6 = nn.Conv2d(64, 64, 3)\n",
    "        self.relu_7_7 = nn.ReLU()\n",
    "        \n",
    "        # 1x1 conv ~= fc; n_classes = 9\n",
    "        self.conv_8_1 = nn.Conv2d(64, 9, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv_1_1(x)\n",
    "        x = self.relu_1_2(x)\n",
    "        x = self.conv_1_3(x)\n",
    "        x_residual_1 = self.relu_1_4(x)\n",
    "        x = self.pool_1_5(x_residual_1)\n",
    "        \n",
    "        x = self.conv_2_1(x)\n",
    "        x = self.relu_2_2(x)        \n",
    "        x = self.conv_2_3(x)\n",
    "        x_residual_2 = self.relu_2_4(x)        \n",
    "        x = self.pool_2_5(x_residual_2)\n",
    "        \n",
    "        x = self.conv_3_1(x)\n",
    "        x = self.relu_3_2(x)        \n",
    "        x = self.conv_3_3(x)\n",
    "        x_residual_3 = self.relu_3_4(x)\n",
    "        x = self.pool_3_5(x_residual_3)\n",
    "        \n",
    "        x = self.conv_4_1(x)\n",
    "        x = self.relu_4_2(x)\n",
    "        x = self.conv_4_3(x)\n",
    "        x = self.relu_4_4(x)\n",
    "        \n",
    "        x = self.deconv_5_1(x)\n",
    "        x = self.concat_5_3(self.c_crop_5_2(x_residual_3), x)\n",
    "        x = self.conv_5_4(x)\n",
    "        x = self.relu_5_5(x)\n",
    "        x = self.conv_5_6(x)\n",
    "        x = self.relu_5_7(x)\n",
    "        \n",
    "        x = self.deconv_6_1(x)\n",
    "        x = self.concat_6_3(self.c_crop_6_2(x_residual_2), x)\n",
    "        x = self.conv_6_4(x)\n",
    "        x = self.relu_6_5(x)\n",
    "        x = self.conv_6_6(x)\n",
    "        x = self.relu_6_7(x)\n",
    "        \n",
    "        x = self.deconv_7_1(x)\n",
    "        x = self.concat_7_3(self.c_crop_7_2(x_residual_1), x)\n",
    "        x = self.conv_7_4(x)\n",
    "        x = self.relu_7_5(x)\n",
    "        x = self.conv_7_6(x)\n",
    "        x = self.relu_7_7(x)\n",
    "        \n",
    "        x = self.conv_8_1(x)\n",
    "        return x\n",
    "\n",
    "from pathlib import Path\n",
    "dataroot = Path('/spell/bob-ross-kaggle-dataset/')\n",
    "dataset = BobRossSegmentedImagesDataset(dataroot)\n",
    "dataloader = DataLoader(dataset, shuffle=True)\n",
    "\n",
    "import numpy as np\n",
    "import torch.optim as optim\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "kf = KFold(n_splits=NUM_FOLDS, shuffle=True)\n",
    "idxs = list(range(len(dataset)))\n",
    "for fold, (train_idxs, test_idxs) in enumerate(kf.split(idxs)):\n",
    "    writer = SummaryWriter(f'/spell/tensorboards/experiment_3_fold_{fold}')\n",
    "    model = UNet()\n",
    "    model.cuda()\n",
    "    \n",
    "    for epoch in range(NUM_EPOCHS):\n",
    "        losses = []\n",
    "\n",
    "        for i, train_idx in enumerate(train_idxs):\n",
    "            batch, segmap = dataset[i]\n",
    "\n",
    "            batch = batch[None].cuda()\n",
    "            segmap = torch.tensor(segmap[None]).cuda()\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            output = model(batch)\n",
    "            loss = criterion(output, segmap)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            curr_loss = loss.item()\n",
    "            if i % 50 == 0:\n",
    "                print(\n",
    "                    f'Finished fold {fold}, epoch {epoch}, batch {i}. Loss: {curr_loss:.3f}.'\n",
    "                )\n",
    "\n",
    "            writer.add_scalar(\n",
    "                'training loss', curr_loss, epoch * len(dataloader) + i\n",
    "            )\n",
    "            losses.append(curr_loss)\n",
    "\n",
    "        print(\n",
    "            f'Finished epoch {epoch}. '\n",
    "            f'avg loss: {np.mean(losses)}; median loss: {np.min(losses)}'\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `pytorch` dataset and dataloder interface do not support cross-validation train-test splits out-of-the-box.\n",
    "\n",
    "There's a couple of ways to get around this. The lightweight way is to implement it ourselves, as here. Recall that `KFold` just draws indices, so we can pass a range of integers, get the indices, and then load the dataset along these indices. This is what I've done here. Notes on this approach:\n",
    "\n",
    "* Lightweight, minimizes code modification.\n",
    "* Have to fall back from using the `DataLoader` class to implementing data loading ourselves, drawing directly from the `Dataset` class instead. This requires many annoying small changes, and we lose all of the nice features `DataLoader` provides, e.g. concurrent dataset loading, automatic data batching, etcetera. For more complex datasets this approach is not going to work.\n",
    "\n",
    "One alternative is using `skorch`. `skorch` is a `sklearn` API wrapper on PyTorch, which brings PyTorch in line with the `scikit-learn` API and allows the models to be used with `sklearn` core. Of course we know from experience with `keras` that this does *not* mean compatibility with the broader `sklearn` ecosystem, unfortunately, but it should mean compatibility with the `sklearn` library itself. Of course `skorch` has the obvious downsides:\n",
    "\n",
    "* It's another layer of abstraction, which can leak. Without more experience with it I can't assess how much of a risk there is of this.\n",
    "* It's a higher-level model wrapper, so may require workarounds to be compatible with other tools that rely on the direct PyTorch interface.\n",
    "\n",
    "Let's try the `skorch` approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%writefile ../models/model_3.py\n",
    "\n",
    "NUM_EPOCHS = 2\n",
    "NUM_FOLDS = 3\n",
    "\n",
    "\n",
    "import torch\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from torchvision import transforms\n",
    "\n",
    "\n",
    "class BobRossSegmentedImagesDataset(Dataset):\n",
    "    def __init__(self, dataroot):\n",
    "        super().__init__()\n",
    "        self.dataroot = dataroot\n",
    "        self.imgs = list((self.dataroot / 'train' / 'images').rglob('*.png'))\n",
    "        self.segs = list((self.dataroot / 'train' / 'labels').rglob('*.png'))\n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.Resize((256, 256)), transforms.ToTensor()\n",
    "        ])\n",
    "        self.color_key = {\n",
    "            3 : 0,\n",
    "            5: 1,\n",
    "            10: 2,\n",
    "            14: 3,\n",
    "            17: 4,\n",
    "            18: 5,\n",
    "            22: 6,\n",
    "            27: 7,\n",
    "            61: 8\n",
    "        }\n",
    "        assert len(self.imgs) == len(self.segs)\n",
    "        # TODO: remean images to N(0, 1)?\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.imgs)\n",
    "    \n",
    "    def __getitem__(self, i):\n",
    "        def translate(x):\n",
    "            return self.color_key[x]\n",
    "        translate = np.vectorize(translate)\n",
    "        \n",
    "        img = Image.open(self.imgs[i])\n",
    "        img = self.transform(img)\n",
    "        \n",
    "        seg = Image.open(self.segs[i])\n",
    "        seg = seg.resize((256, 256))\n",
    "        \n",
    "        # Labels are in the ADE20K ontology and are not consequetive,\n",
    "        # we have to apply a remap operation over the labels in a just-in-time\n",
    "        # manner. This slows things down, but it's fine, this is just a demo\n",
    "        # anyway.\n",
    "        seg = translate(np.array(seg)).astype('int64')\n",
    "        \n",
    "        # One-hot encode the segmentation mask.\n",
    "        # def ohe_mat(segmap):\n",
    "        #     return np.array(\n",
    "        #         list(\n",
    "        #             np.array(segmap) == i for i in range(9)\n",
    "        #         )\n",
    "        #     ).astype(int).reshape(9, 256, 256)\n",
    "        # seg = ohe_mat(seg)\n",
    "        \n",
    "        # Additionally, the original UNet implementation outputs a segmentation map\n",
    "        # for a subset of the overall image, not the image as a whole! With this input\n",
    "        # size the segmentation map targeted is a (164, 164) center crop.\n",
    "        seg = seg[46:210, 46:210]\n",
    "        \n",
    "        return img, seg\n",
    "    \n",
    "    \n",
    "from torch import nn\n",
    "\n",
    "class UNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv_1_1 = nn.Conv2d(3, 64, 3)\n",
    "        self.relu_1_2 = nn.ReLU()\n",
    "        self.conv_1_3 = nn.Conv2d(64, 64, 3)\n",
    "        self.relu_1_4 = nn.ReLU()\n",
    "        self.pool_1_5 = nn.MaxPool2d(2)\n",
    "        \n",
    "        self.conv_2_1 = nn.Conv2d(64, 128, 3)\n",
    "        self.relu_2_2 = nn.ReLU()\n",
    "        self.conv_2_3 = nn.Conv2d(128, 128, 3)\n",
    "        self.relu_2_4 = nn.ReLU()        \n",
    "        self.pool_2_5 = nn.MaxPool2d(2)\n",
    "        \n",
    "        self.conv_3_1 = nn.Conv2d(128, 256, 3)\n",
    "        self.relu_3_2 = nn.ReLU()\n",
    "        self.conv_3_3 = nn.Conv2d(256, 256, 3)\n",
    "        self.relu_3_4 = nn.ReLU()\n",
    "        self.pool_3_5 = nn.MaxPool2d(2)\n",
    "        \n",
    "        self.conv_4_1 = nn.Conv2d(256, 512, 3)\n",
    "        self.relu_4_2 = nn.ReLU()\n",
    "        self.conv_4_3 = nn.Conv2d(512, 512, 3)\n",
    "        self.relu_4_4 = nn.ReLU()\n",
    "        \n",
    "        # deconv is the '2D transposed convolution operator'\n",
    "        self.deconv_5_1 = nn.ConvTranspose2d(512, 256, (2, 2), 2)\n",
    "        # 61x61 -> 48x48 crop\n",
    "        self.c_crop_5_2 = lambda x: x[:, :, 6:54, 6:54]\n",
    "        self.concat_5_3 = lambda x, y: torch.cat((x, y), dim=1)\n",
    "        self.conv_5_4 = nn.Conv2d(512, 256, 3)\n",
    "        self.relu_5_5 = nn.ReLU()\n",
    "        self.conv_5_6 = nn.Conv2d(256, 256, 3)\n",
    "        self.relu_5_7 = nn.ReLU()\n",
    "        \n",
    "        self.deconv_6_1 = nn.ConvTranspose2d(256, 128, (2, 2), 2)\n",
    "        # 121x121 -> 88x88 crop\n",
    "        self.c_crop_6_2 = lambda x: x[:, :, 17:105, 17:105]\n",
    "        self.concat_6_3 = lambda x, y: torch.cat((x, y), dim=1)\n",
    "        self.conv_6_4 = nn.Conv2d(256, 128, 3)\n",
    "        self.relu_6_5 = nn.ReLU()\n",
    "        self.conv_6_6 = nn.Conv2d(128, 128, 3)\n",
    "        self.relu_6_7 = nn.ReLU()\n",
    "        \n",
    "        self.deconv_7_1 = nn.ConvTranspose2d(128, 64, (2, 2), 2)\n",
    "        # 252x252 -> 168x168 crop\n",
    "        self.c_crop_7_2 = lambda x: x[:, :, 44:212, 44:212]\n",
    "        self.concat_7_3 = lambda x, y: torch.cat((x, y), dim=1)\n",
    "        self.conv_7_4 = nn.Conv2d(128, 64, 3)\n",
    "        self.relu_7_5 = nn.ReLU()\n",
    "        self.conv_7_6 = nn.Conv2d(64, 64, 3)\n",
    "        self.relu_7_7 = nn.ReLU()\n",
    "        \n",
    "        # 1x1 conv ~= fc; n_classes = 9\n",
    "        self.conv_8_1 = nn.Conv2d(64, 9, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv_1_1(x)\n",
    "        x = self.relu_1_2(x)\n",
    "        x = self.conv_1_3(x)\n",
    "        x_residual_1 = self.relu_1_4(x)\n",
    "        x = self.pool_1_5(x_residual_1)\n",
    "        \n",
    "        x = self.conv_2_1(x)\n",
    "        x = self.relu_2_2(x)        \n",
    "        x = self.conv_2_3(x)\n",
    "        x_residual_2 = self.relu_2_4(x)        \n",
    "        x = self.pool_2_5(x_residual_2)\n",
    "        \n",
    "        x = self.conv_3_1(x)\n",
    "        x = self.relu_3_2(x)        \n",
    "        x = self.conv_3_3(x)\n",
    "        x_residual_3 = self.relu_3_4(x)\n",
    "        x = self.pool_3_5(x_residual_3)\n",
    "        \n",
    "        x = self.conv_4_1(x)\n",
    "        x = self.relu_4_2(x)\n",
    "        x = self.conv_4_3(x)\n",
    "        x = self.relu_4_4(x)\n",
    "        \n",
    "        x = self.deconv_5_1(x)\n",
    "        x = self.concat_5_3(self.c_crop_5_2(x_residual_3), x)\n",
    "        x = self.conv_5_4(x)\n",
    "        x = self.relu_5_5(x)\n",
    "        x = self.conv_5_6(x)\n",
    "        x = self.relu_5_7(x)\n",
    "        \n",
    "        x = self.deconv_6_1(x)\n",
    "        x = self.concat_6_3(self.c_crop_6_2(x_residual_2), x)\n",
    "        x = self.conv_6_4(x)\n",
    "        x = self.relu_6_5(x)\n",
    "        x = self.conv_6_6(x)\n",
    "        x = self.relu_6_7(x)\n",
    "        \n",
    "        x = self.deconv_7_1(x)\n",
    "        x = self.concat_7_3(self.c_crop_7_2(x_residual_1), x)\n",
    "        x = self.conv_7_4(x)\n",
    "        x = self.relu_7_5(x)\n",
    "        x = self.conv_7_6(x)\n",
    "        x = self.relu_7_7(x)\n",
    "        \n",
    "        x = self.conv_8_1(x)\n",
    "        return x\n",
    "\n",
    "from pathlib import Path\n",
    "dataroot = Path('/spell/bob-ross-kaggle-dataset/')\n",
    "dataset = BobRossSegmentedImagesDataset(dataroot)\n",
    "dataloader = DataLoader(dataset, shuffle=True)\n",
    "\n",
    "model = UNet()\n",
    "model.cuda()\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import torch.optim as optim\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skorch.classifier import NeuralNetClassifier\n",
    "model = NeuralNetClassifier(\n",
    "    model,\n",
    "    criterion=criterion,\n",
    "    optimizer=optimizer,\n",
    "    max_epochs=NUM_EPOCHS,\n",
    "    batch_size=1,\n",
    "    # passing an initialized dataset object means fit is unparameterized\n",
    "    dataset=dataset,\n",
    "    device=0\n",
    "    # CV is controlled by the train_test parameter, default is 5-fold CV?\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "forward() missing 2 required positional arguments: 'input' and 'target'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-b8980ff890b6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/skorch/classifier.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    147\u001b[0m         \u001b[0;31m# this is actually a pylint bug:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m         \u001b[0;31m# https://github.com/PyCQA/pylint/issues/1085\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 149\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNeuralNetClassifier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/skorch/net.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    844\u001b[0m         \"\"\"\n\u001b[1;32m    845\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarm_start\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minitialized_\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 846\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minitialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    847\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    848\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpartial_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/skorch/net.py\u001b[0m in \u001b[0;36minitialize\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    541\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minitialize_virtual_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    542\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minitialize_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 543\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minitialize_criterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    544\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minitialize_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    545\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minitialize_optimizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/skorch/net.py\u001b[0m in \u001b[0;36minitialize_criterion\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    429\u001b[0m         \u001b[0;34m\"\"\"Initializes the criterion.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    430\u001b[0m         \u001b[0mcriterion_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_params_for\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'criterion'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 431\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcriterion_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mcriterion_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    432\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcriterion_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    433\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcriterion_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcriterion_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    545\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 547\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    548\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: forward() missing 2 required positional arguments: 'input' and 'target'"
     ]
    }
   ],
   "source": [
    "model.fit(dataset, None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`skorch` is sufficiently complex that I can't get it working without going through the tutorial materials first. I'm not too keen on doing this right right now, so I'll stop here with this approach.\n",
    "\n",
    "Review of this part of `skorch`. `skorch` has its own `Dataset` implementation which has wider input compatibility than the PyTorch `Dataset` implementation, but acts as a thin wrapper, and you can use a PyTorch `Dataset` directly. `skorch` reuses the PyTorch `DataLoader` without modification.\n",
    "\n",
    "By default `skorch` uses `train_test` with five-fold `skorch.CVSplit`. `skorch` *only makes a single model split* by default; so I guess it's really just a `train_test_split`?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's return back to our bootstrapped approach and run that model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0mHello, Aleksey Bilogur!\n",
      "\u001b[0m\u001b[0m"
     ]
    }
   ],
   "source": [
    "!spell login --identity #### --password ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Everything up-to-date\n",
      "\u001b[0m💫 Casting spell #156…\n",
      "\u001b[0m✨ Stop viewing logs with ^C\n",
      "\u001b[0m\u001b[K\u001b[0m\u001b[?25h\u001b[0m✨ Machine_Requested… done\n",
      "\u001b[0m\u001b[K\u001b[0m\u001b[?25h\u001b[0m✨ Building… done tagged registry-1.spell:80/residentmario/2dc6b76f8dc6……[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[K\u001b[0m\u001b[?25h\u001b[0m✨ Mounting… doneting[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\n",
      "\u001b[0m✨ \u001b[0mRun is running\n",
      "\u001b[0m0_initial_model.ipynb\n",
      "\u001b[0m1_initial_spell_model.ipynb\n",
      "\u001b[0m2_with_tensorboard.ipynb\n",
      "\u001b[0m3_cross_validated.ipynb\n",
      "\u001b[0mls: cannot access 'models': No such file or directory\n",
      "\u001b[0mpython: can't open file 'models/model_3.py': [Errno 2] No such file or directory\n",
      "\u001b[0m\u001b[K\u001b[0m\u001b[?25h\u001b[0m✨ Saving… doner modified or new files from the run\u001b[0m\n",
      "\u001b[0m\u001b[K\u001b[0m\u001b[?25h\u001b[0m✨ Pushing… donengg\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\n",
      "\u001b[0m🎉 \u001b[0mTotal run time: 16.440464s\n",
      "\u001b[0m🎉 \u001b[0mRun 156 complete\n",
      "\u001b[0m\u001b[K\u001b[0m\u001b[?25h\u001b[0m\u001b[0m"
     ]
    }
   ],
   "source": [
    "# rsync not installed error, have to put rsync in the apt-get field of the workspace\n",
    "# 'pytorch' framework does not support tensorboard!?!\n",
    "# Use default, which does.\n",
    "# --framework 'pytorch'\n",
    "\n",
    "!spell run 'ls .; ls models; python models/model_3.py'\\\n",
    "    --machine-type 'K80'\\\n",
    "    --mount 'uploads/bob-ross-kaggle-dataset':'/spell/bob-ross-kaggle-dataset'\\\n",
    "    --tensorboard-dir '/spell/tensorboards/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I expect the `spell run` command to mount the root of the current Git project, e.g. the folder nearest to the current working directory in the file hierarchy containing the `.git` repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m💫 Casting spell #157…\n",
      "\u001b[0m✨ Stop viewing logs with ^C\n",
      "\u001b[0m\u001b[K\u001b[0m\u001b[?25h\u001b[0m✨ Building… doneuired -- commencing run\u001b[0m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[K\u001b[0m\u001b[?25h\u001b[0m✨ Machine_Requested… done tagged registry-1.spell:80/remote_content_15……[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[K\u001b[0m\u001b[?25h\u001b[0m✨ Mounting… doneting\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\n",
      "\u001b[0m✨ \u001b[0mRun is running\n",
      "\u001b[0mbob-ross-kaggle-dataset\n",
      "\u001b[0mmodels\n",
      "\u001b[0mnotebooks\n",
      "\u001b[0mREADME.md\n",
      "\u001b[0mtensorboards\n",
      "\u001b[0mmodel_3.py\n",
      "\u001b[0mFinished fold 0, epoch 0, batch 0. Loss: 2.195.\n",
      "\u001b[0m^C\n",
      "\n",
      "\u001b[0m✨ Your run is still running remotely.\n",
      "\u001b[0m✨ Use 'spell kill 157' to terminate your run\n",
      "\u001b[0m✨ Use 'spell logs 157' to view logs again\n",
      "\u001b[0m\u001b[K\u001b[0m\u001b[?25h\u001b[0m\u001b[0m"
     ]
    }
   ],
   "source": [
    "!spell run 'ls .; ls models; python models/model_3.py'\\\n",
    "    --machine-type 'K80'\\\n",
    "    --mount 'uploads/bob-ross-kaggle-dataset':'/spell/bob-ross-kaggle-dataset'\\\n",
    "    --github-url 'https://github.com/ResidentMario/unet-pytorch.git'\\\n",
    "    --tensorboard-dir '/spell/tensorboards/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

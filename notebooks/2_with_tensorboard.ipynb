{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we hook up the basic UNet model we've trained to Tensorboard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from torchvision import transforms\n",
    "\n",
    "\n",
    "class BobRossSegmentedImagesDataset(Dataset):\n",
    "    def __init__(self, dataroot):\n",
    "        super().__init__()\n",
    "        self.dataroot = dataroot\n",
    "        self.imgs = list((self.dataroot / 'train' / 'images').rglob('*.png'))\n",
    "        self.segs = list((self.dataroot / 'train' / 'labels').rglob('*.png'))\n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.Resize((256, 256)), transforms.ToTensor()\n",
    "        ])\n",
    "        self.color_key = {\n",
    "            3 : 0,\n",
    "            5: 1,\n",
    "            10: 2,\n",
    "            14: 3,\n",
    "            17: 4,\n",
    "            18: 5,\n",
    "            22: 6,\n",
    "            27: 7,\n",
    "            61: 8\n",
    "        }\n",
    "        assert len(self.imgs) == len(self.segs)\n",
    "        # TODO: remean images to N(0, 1)?\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.imgs)\n",
    "    \n",
    "    def __getitem__(self, i):\n",
    "        def translate(x):\n",
    "            return self.color_key[x]\n",
    "        translate = np.vectorize(translate)\n",
    "        \n",
    "        img = Image.open(self.imgs[i])\n",
    "        img = self.transform(img)\n",
    "        \n",
    "        seg = Image.open(self.segs[i])\n",
    "        seg = seg.resize((256, 256))\n",
    "        \n",
    "        # Labels are in the ADE20K ontology and are not consequetive,\n",
    "        # we have to apply a remap operation over the labels in a just-in-time\n",
    "        # manner. This slows things down, but it's fine, this is just a demo\n",
    "        # anyway.\n",
    "        seg = translate(np.array(seg)).astype('int64')\n",
    "        \n",
    "        # One-hot encode the segmentation mask.\n",
    "        # def ohe_mat(segmap):\n",
    "        #     return np.array(\n",
    "        #         list(\n",
    "        #             np.array(segmap) == i for i in range(9)\n",
    "        #         )\n",
    "        #     ).astype(int).reshape(9, 256, 256)\n",
    "        # seg = ohe_mat(seg)\n",
    "        \n",
    "        # Additionally, the original UNet implementation outputs a segmentation map\n",
    "        # for a subset of the overall image, not the image as a whole! With this input\n",
    "        # size the segmentation map targeted is a (164, 164) center crop.\n",
    "        seg = seg[46:210, 46:210]\n",
    "        \n",
    "        return img, seg\n",
    "\n",
    "    \n",
    "from torch import nn\n",
    "\n",
    "class UNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv_1_1 = nn.Conv2d(3, 64, 3)\n",
    "        self.relu_1_2 = nn.ReLU()\n",
    "        self.conv_1_3 = nn.Conv2d(64, 64, 3)\n",
    "        self.relu_1_4 = nn.ReLU()\n",
    "        self.pool_1_5 = nn.MaxPool2d(2)\n",
    "        \n",
    "        self.conv_2_1 = nn.Conv2d(64, 128, 3)\n",
    "        self.relu_2_2 = nn.ReLU()\n",
    "        self.conv_2_3 = nn.Conv2d(128, 128, 3)\n",
    "        self.relu_2_4 = nn.ReLU()        \n",
    "        self.pool_2_5 = nn.MaxPool2d(2)\n",
    "        \n",
    "        self.conv_3_1 = nn.Conv2d(128, 256, 3)\n",
    "        self.relu_3_2 = nn.ReLU()\n",
    "        self.conv_3_3 = nn.Conv2d(256, 256, 3)\n",
    "        self.relu_3_4 = nn.ReLU()\n",
    "        self.pool_3_5 = nn.MaxPool2d(2)\n",
    "        \n",
    "        self.conv_4_1 = nn.Conv2d(256, 512, 3)\n",
    "        self.relu_4_2 = nn.ReLU()\n",
    "        self.conv_4_3 = nn.Conv2d(512, 512, 3)\n",
    "        self.relu_4_4 = nn.ReLU()\n",
    "        \n",
    "        # deconv is the '2D transposed convolution operator'\n",
    "        self.deconv_5_1 = nn.ConvTranspose2d(512, 256, (2, 2), 2)\n",
    "        # 61x61 -> 48x48 crop\n",
    "        self.c_crop_5_2 = lambda x: x[:, :, 6:54, 6:54]\n",
    "        self.concat_5_3 = lambda x, y: torch.cat((x, y), dim=1)\n",
    "        self.conv_5_4 = nn.Conv2d(512, 256, 3)\n",
    "        self.relu_5_5 = nn.ReLU()\n",
    "        self.conv_5_6 = nn.Conv2d(256, 256, 3)\n",
    "        self.relu_5_7 = nn.ReLU()\n",
    "        \n",
    "        self.deconv_6_1 = nn.ConvTranspose2d(256, 128, (2, 2), 2)\n",
    "        # 121x121 -> 88x88 crop\n",
    "        self.c_crop_6_2 = lambda x: x[:, :, 17:105, 17:105]\n",
    "        self.concat_6_3 = lambda x, y: torch.cat((x, y), dim=1)\n",
    "        self.conv_6_4 = nn.Conv2d(256, 128, 3)\n",
    "        self.relu_6_5 = nn.ReLU()\n",
    "        self.conv_6_6 = nn.Conv2d(128, 128, 3)\n",
    "        self.relu_6_7 = nn.ReLU()\n",
    "        \n",
    "        self.deconv_7_1 = nn.ConvTranspose2d(128, 64, (2, 2), 2)\n",
    "        # 252x252 -> 168x168 crop\n",
    "        self.c_crop_7_2 = lambda x: x[:, :, 44:212, 44:212]\n",
    "        self.concat_7_3 = lambda x, y: torch.cat((x, y), dim=1)\n",
    "        self.conv_7_4 = nn.Conv2d(128, 64, 3)\n",
    "        self.relu_7_5 = nn.ReLU()\n",
    "        self.conv_7_6 = nn.Conv2d(64, 64, 3)\n",
    "        self.relu_7_7 = nn.ReLU()\n",
    "        \n",
    "        # 1x1 conv ~= fc; n_classes = 9\n",
    "        self.conv_8_1 = nn.Conv2d(64, 9, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv_1_1(x)\n",
    "        x = self.relu_1_2(x)\n",
    "        x = self.conv_1_3(x)\n",
    "        x_residual_1 = self.relu_1_4(x)\n",
    "        x = self.pool_1_5(x_residual_1)\n",
    "        \n",
    "        x = self.conv_2_1(x)\n",
    "        x = self.relu_2_2(x)        \n",
    "        x = self.conv_2_3(x)\n",
    "        x_residual_2 = self.relu_2_4(x)        \n",
    "        x = self.pool_2_5(x_residual_2)\n",
    "        \n",
    "        x = self.conv_3_1(x)\n",
    "        x = self.relu_3_2(x)        \n",
    "        x = self.conv_3_3(x)\n",
    "        x_residual_3 = self.relu_3_4(x)\n",
    "        x = self.pool_3_5(x_residual_3)\n",
    "        \n",
    "        x = self.conv_4_1(x)\n",
    "        x = self.relu_4_2(x)\n",
    "        x = self.conv_4_3(x)\n",
    "        x = self.relu_4_4(x)\n",
    "        \n",
    "        x = self.deconv_5_1(x)\n",
    "        x = self.concat_5_3(self.c_crop_5_2(x_residual_3), x)\n",
    "        x = self.conv_5_4(x)\n",
    "        x = self.relu_5_5(x)\n",
    "        x = self.conv_5_6(x)\n",
    "        x = self.relu_5_7(x)\n",
    "        \n",
    "        x = self.deconv_6_1(x)\n",
    "        x = self.concat_6_3(self.c_crop_6_2(x_residual_2), x)\n",
    "        x = self.conv_6_4(x)\n",
    "        x = self.relu_6_5(x)\n",
    "        x = self.conv_6_6(x)\n",
    "        x = self.relu_6_7(x)\n",
    "        \n",
    "        x = self.deconv_7_1(x)\n",
    "        x = self.concat_7_3(self.c_crop_7_2(x_residual_1), x)\n",
    "        x = self.conv_7_4(x)\n",
    "        x = self.relu_7_5(x)\n",
    "        x = self.conv_7_6(x)\n",
    "        x = self.relu_7_7(x)\n",
    "        \n",
    "        x = self.conv_8_1(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "dataroot = Path('/spell/bob-ross-kaggle-dataset/')\n",
    "dataset = BobRossSegmentedImagesDataset(dataroot)\n",
    "dataloader = DataLoader(dataset, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UNet(\n",
       "  (conv_1_1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (relu_1_2): ReLU()\n",
       "  (conv_1_3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (relu_1_4): ReLU()\n",
       "  (pool_1_5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv_2_1): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (relu_2_2): ReLU()\n",
       "  (conv_2_3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (relu_2_4): ReLU()\n",
       "  (pool_2_5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv_3_1): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (relu_3_2): ReLU()\n",
       "  (conv_3_3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (relu_3_4): ReLU()\n",
       "  (pool_3_5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv_4_1): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (relu_4_2): ReLU()\n",
       "  (conv_4_3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (relu_4_4): ReLU()\n",
       "  (deconv_5_1): ConvTranspose2d(512, 256, kernel_size=(2, 2), stride=(2, 2))\n",
       "  (conv_5_4): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (relu_5_5): ReLU()\n",
       "  (conv_5_6): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (relu_5_7): ReLU()\n",
       "  (deconv_6_1): ConvTranspose2d(256, 128, kernel_size=(2, 2), stride=(2, 2))\n",
       "  (conv_6_4): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (relu_6_5): ReLU()\n",
       "  (conv_6_6): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (relu_6_7): ReLU()\n",
       "  (deconv_7_1): ConvTranspose2d(128, 64, kernel_size=(2, 2), stride=(2, 2))\n",
       "  (conv_7_4): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (relu_7_5): ReLU()\n",
       "  (conv_7_6): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (relu_7_7): ReLU()\n",
       "  (conv_8_1): Conv2d(64, 9, kernel_size=(1, 1), stride=(1, 1))\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = UNet()\n",
    "model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "writer = SummaryWriter('/spell/tensorboards/experiment_2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished epoch 0, batch 0. Loss: 1.272.\n",
      "Finished epoch 0, batch 50. Loss: 1.159.\n",
      "Finished epoch 0, batch 100. Loss: 1.062.\n",
      "Finished epoch 0, batch 150. Loss: 1.410.\n",
      "Finished epoch 0, batch 200. Loss: 3.235.\n",
      "Finished epoch 0, batch 250. Loss: 1.391.\n",
      "Finished epoch 0. avg loss: 1.5243689935520826; median loss: 0.5609884262084961\n",
      "Finished epoch 1, batch 0. Loss: 2.595.\n",
      "Finished epoch 1, batch 50. Loss: 1.595.\n",
      "Finished epoch 1, batch 100. Loss: 1.654.\n",
      "Finished epoch 1, batch 150. Loss: 0.997.\n",
      "Finished epoch 1, batch 200. Loss: 1.600.\n",
      "Finished epoch 1, batch 250. Loss: 1.320.\n",
      "Finished epoch 1. avg loss: 1.4904698867246924; median loss: 0.6060738563537598\n",
      "Finished epoch 2, batch 0. Loss: 1.471.\n",
      "Finished epoch 2, batch 50. Loss: 1.290.\n",
      "Finished epoch 2, batch 100. Loss: 1.505.\n",
      "Finished epoch 2, batch 150. Loss: 1.191.\n",
      "Finished epoch 2, batch 200. Loss: 1.464.\n",
      "Finished epoch 2, batch 250. Loss: 1.682.\n",
      "Finished epoch 2. avg loss: 1.488304772462503; median loss: 0.4966057538986206\n",
      "Finished epoch 3, batch 0. Loss: 1.774.\n",
      "Finished epoch 3, batch 50. Loss: 1.365.\n",
      "Finished epoch 3, batch 100. Loss: 0.787.\n",
      "Finished epoch 3, batch 150. Loss: 1.571.\n",
      "Finished epoch 3, batch 200. Loss: 1.678.\n",
      "Finished epoch 3, batch 250. Loss: 1.144.\n",
      "Finished epoch 3. avg loss: 1.4742064630367842; median loss: 0.6821351647377014\n",
      "Finished epoch 4, batch 0. Loss: 1.432.\n",
      "Finished epoch 4, batch 50. Loss: 1.496.\n",
      "Finished epoch 4, batch 100. Loss: 1.085.\n",
      "Finished epoch 4, batch 150. Loss: 2.410.\n",
      "Finished epoch 4, batch 200. Loss: 1.138.\n",
      "Finished epoch 4, batch 250. Loss: 1.254.\n",
      "Finished epoch 4. avg loss: 1.4516257883543038; median loss: 0.5873275399208069\n",
      "Finished epoch 5, batch 0. Loss: 1.669.\n",
      "Finished epoch 5, batch 50. Loss: 1.109.\n",
      "Finished epoch 5, batch 100. Loss: 0.820.\n",
      "Finished epoch 5, batch 150. Loss: 0.911.\n",
      "Finished epoch 5, batch 200. Loss: 0.942.\n",
      "Finished epoch 5, batch 250. Loss: 2.411.\n",
      "Finished epoch 5. avg loss: 1.453476206239951; median loss: 0.6252924799919128\n",
      "Finished epoch 6, batch 0. Loss: 2.212.\n",
      "Finished epoch 6, batch 50. Loss: 1.333.\n",
      "Finished epoch 6, batch 100. Loss: 2.070.\n",
      "Finished epoch 6, batch 150. Loss: 3.142.\n",
      "Finished epoch 6, batch 200. Loss: 1.110.\n",
      "Finished epoch 6, batch 250. Loss: 1.394.\n",
      "Finished epoch 6. avg loss: 1.4450993421543168; median loss: 0.5562487244606018\n",
      "Finished epoch 7, batch 0. Loss: 1.388.\n",
      "Finished epoch 7, batch 50. Loss: 1.318.\n",
      "Finished epoch 7, batch 100. Loss: 1.216.\n",
      "Finished epoch 7, batch 150. Loss: 1.016.\n",
      "Finished epoch 7, batch 200. Loss: 1.471.\n",
      "Finished epoch 7, batch 250. Loss: 1.923.\n",
      "Finished epoch 7. avg loss: 1.452303556569544; median loss: 0.6162434220314026\n",
      "Finished epoch 8, batch 0. Loss: 2.116.\n",
      "Finished epoch 8, batch 50. Loss: 1.543.\n",
      "Finished epoch 8, batch 100. Loss: 1.354.\n",
      "Finished epoch 8, batch 150. Loss: 1.254.\n",
      "Finished epoch 8, batch 200. Loss: 1.014.\n",
      "Finished epoch 8, batch 250. Loss: 2.007.\n",
      "Finished epoch 8. avg loss: 1.429087301174483; median loss: 0.5116059184074402\n",
      "Finished epoch 9, batch 0. Loss: 1.290.\n",
      "Finished epoch 9, batch 50. Loss: 1.356.\n",
      "Finished epoch 9, batch 100. Loss: 1.153.\n",
      "Finished epoch 9, batch 150. Loss: 1.507.\n",
      "Finished epoch 9, batch 200. Loss: 1.001.\n",
      "Finished epoch 9, batch 250. Loss: 0.961.\n",
      "Finished epoch 9. avg loss: 1.4025175482390886; median loss: 0.48811689019203186\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch.optim as optim\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "\n",
    "for epoch in range(10):\n",
    "    losses = []\n",
    "    \n",
    "    for i, (batch, segmap) in enumerate(dataloader):\n",
    "        \n",
    "        batch = batch.cuda()\n",
    "        segmap = segmap.cuda()\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        output = model(batch)\n",
    "        loss = criterion(output, segmap)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        curr_loss = loss.item()\n",
    "        if i % 50 == 0:\n",
    "            print(f'Finished epoch {epoch}, batch {i}. Loss: {curr_loss:.3f}.')\n",
    "        \n",
    "        writer.add_scalar(\n",
    "            'training loss', curr_loss, epoch * len(dataloader) + i\n",
    "        )\n",
    "        losses.append(curr_loss)\n",
    "    \n",
    "    print(\n",
    "        f'Finished epoch {epoch}. '\n",
    "        f'avg loss: {np.mean(losses)}; median loss: {np.min(losses)}'\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There's some interesting product weirdness around the [JupyterLab Tensorboard integration](https://github.com/chaoleili/jupyterlab_tensorboard).\n",
    "\n",
    "There are two ways to open a Tensorboard window in JupyterLab:\n",
    "\n",
    "* By clicking on a new \"Tensorboard\" tile in the create pane. This is how most people would interact with this feature.\n",
    "* By searching \"Tensorboard\" in the command menu and clicking on \"Create a new tensorboard.\"\n",
    "\n",
    "An important aspect of how Tensorboard works is that all of the information is logged to a file, and that file can be placed anywhere on your machine. When using Tensorboard the old-fashioned way, you specify the path to that file as part of the input to the `tensorboard` CLI command.\n",
    "\n",
    "When launching a Tensorboard via the create tile, Tensorboard is initialized with the default `logdir` argument. The directory chosen is not a modifiable part of the user flow, nor can it be modified in the \"Tensorboards\" pane after-the-fact!\n",
    "\n",
    "The default `logdir` chosen is the root of the JupyterLab directory. This is not at all user discoverable, you have to visit the repo `README.md` to learn this! On Spell this is `/spell/`. This means that the only place you can create Tensorboards visible to Tensorboard instances launched this way is to write them out to the `/spell/` directory, which is poor form.\n",
    "\n",
    "What about launching Tensorboard via the command palette? In this case you can customize the Tensorboard directory. However, likely due to security limitations in place in JupyterLab, it is only possible to specify subpaths relative to the Jupyter Lab root directory&mdash;which is, again, `/spell/`.\n",
    "\n",
    "A good idea: making a PR against the Tensorboard integrations to allow inline setting of the logdir path when clicking on the pane; and allow updating the `logdir` location later by right-clicking on the Tensorboard in the `Tensorboards` menu later.\n",
    "\n",
    "There's also some funkiness in the open tabs menu with Tensorboard instances appearing out-of-line with the rest of the tabs listed there that can be fixed.\n",
    "\n",
    "Dumping the Tensorboard runs in the top-level Spell directory is a bad idea. Ultimately the correct flow *at this time* (when running from a Jupyter instance) is to use a path like `/spell/tensorboard/experiment_2` and launch there using the command palette:\n",
    "\n",
    "![](https://i.imgur.com/TKawv5j.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
